# Amazon Sale Sentiment Analysis & LLM Training Pipeline

## ğŸ“Œ Project Overview

This project automates the **collection, cleaning, and sentiment analysis** of Reddit discussions related to **Amazon sales**.
It extracts customer opinions, identifies trending products, and prepares structured datasets for **training a custom LLM** specialized in e-commerce discussions.

---

## ğŸ¯ Problem Statement

Large-scale e-commerce events (e.g., Amazon Great Indian Festival, Prime Day) generate **thousands of customer comments** daily on online forums.
Manually tracking and analyzing them is **slow and error-prone**.

This project solves that problem by:

* Automating Reddit data collection from sale-related discussions.
* Cleaning and filtering data for **only relevant insights**.
* Applying **AI sentiment analysis** to gauge public opinion.
* Producing datasets ready for **LLM fine-tuning** in retail-specific contexts.

---

## ğŸš€ Features

* Automatic Reddit comment scraping via **PRAW API**.
* Text cleaning & relevance filtering.
* AI-powered **sentiment classification**.
* Raw and processed data saved in CSV format.
* Ready-to-train datasets for custom LLMs.

---

## ğŸ“‚ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw Reddit comments
â”‚   â””â”€â”€ processed/          # Cleaned + sentiment-tagged data
â”‚
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ reddit_scraper.py   # Step 1: Data scraping
â”‚   â”œâ”€â”€ subreddits.txt      # Target subreddits list
â”‚
â”œâ”€â”€ processor/
â”‚   â”œâ”€â”€ sentiment_cleaner.py # Step 2: Cleaning + Sentiment
â”‚   â”œâ”€â”€ utils.py             # Helper functions
â”‚
â”œâ”€â”€ .env                     # Reddit API credentials
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.md                # Documentation
```

---

## ğŸ”„ Workflow

1. **Scraping** â†’ Collect Reddit posts & comments from target subreddits.
2. **Processing** â†’ Clean, filter, and analyze sentiment.
3. **Output** â†’ Store final dataset in `data/processed/` for LLM training.

---

## ğŸ“¦ Dependencies

* Python 3.8+
* PRAW (Reddit API wrapper)
* Pandas (Data processing)
* Requests (API calls)
* Streamlit *(optional, for dashboard)*

Install all with:

```bash
pip install -r requirements.txt
```

---

## ğŸŒ APIs Used

* **Reddit API** (via PRAW) â€“ Fetch posts/comments.
* **Custom AI API** â€“ Sentiment classification.
---

## ğŸ Known Issues

* â€œNo comments foundâ€ if keywords are missing in posts.
* API rate limits may interrupt long scrapes.
* Sarcasm/mixed sentiment can cause misclassification.
---

## ğŸ“š Resources

* [PRAW Docs](https://praw.readthedocs.io/)
* [Reddit API Reference](https://www.reddit.com/dev/api/)
* [Pandas Docs](https://pandas.pydata.org/)
* [Requests Docs](https://requests.readthedocs.io/)

---

## ğŸ’¡ Real-World Applications

* **Market research** for e-commerce trends.
* Tracking **customer sentiment** during big sales.
* Building **domain-specific chatbots** for retail.

---

## ğŸ”® Next Enhancements

* Multi-platform scraping (Flipkart, Twitter/X, etc.).
* Transformer-based **advanced sentiment models**.
* Real-time dashboard visualizations.
* Automated keyword/topic extraction.
* Async scraping for speed & rate-limit handling.

---
